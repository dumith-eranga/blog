---
title: "Zero-Shot Learning"
date: 2023-03-13
---

Machine learning is omnipresent in today's world. It is the magic that runs behind many technological marvels. Between image generation from tools like Stable Diffusion to prompt and response systems like ChatGPT, the essence of the magic lies in the mechanism of identifying and deconstructing input to generate and synthesize the output.

To achieve this, the machine, or more specifically, the model learns by using a massive amount of training data. The process is analogous to how a human, especially a child, is learning. They run through enough training data via observation, reading, listening or doing until a concept is internalised to the level that can be differentiated when encountered in a different context.

One interesting problem in learning is how to recognise something one encounters for the first time. A good example is distinguishing a zebra when the learner is only familiar with horses, and the knowledge that a zebra is like a striped horse. This aspect, called Zero-Shot Learning, is achieved by comparing and contrasting the existing knowledge with the observation presented and using the facts to fill in the gaps.

It is an area where machines can excel over humans. While people tend to forget things over time due to both physical degradation and getting overshadowed by other memories, a machine can readily retrieve all facts in its storage. A person may fail to identify a zebra just because they learned the fact about striped horses ten years ago, but a machine will never go wrong because its memory is always accessible.
 
#machinelearning #ml 

---
[LinkedIn](https://www.linkedin.com/feed/update/urn:li:share:7041069679183851520/)